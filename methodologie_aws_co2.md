# MÃ©thodologie d'Ã‰valuation CO2 Infrastructure AWS

## ðŸŽ¯ **APPROCHES DISPONIBLES**

### 1. **AWS Customer Carbon Footprint Tool (CCFT)** - OFFICIEL
- **AccÃ¨s** : Console AWS Billing > Customer Carbon Footprint Tool
- **MÃ©thodologie** : Version 2.0 (depuis janvier 2025), vÃ©rifiÃ©e par un tiers
- **GranularitÃ©** : Par rÃ©gion AWS, par service (EC2, S3, autres)
- **Format** : MTCO2e (tonnes CO2 Ã©quivalent)
- **DÃ©lai** : DonnÃ©es disponibles avec 3 mois de retard
- **Limites** : Scope 1 et 2 uniquement, pas de temps rÃ©el

### 2. **Outils Open Source** 
- **Cloud Carbon Footprint** : Multi-cloud (AWS, GCP, Azure)
- **Teads Carbon Estimator** : SpÃ©cialisÃ© instances EC2
- **Cloud-Carbon (Giant Swarm)** : BasÃ© sur Cost & Usage Reports

---

## ðŸ“Š **INDICATEURS NÃ‰CESSAIRES**

### **DonnÃ©es d'Infrastructure**
```
âœ“ Type d'instances EC2 (t2.micro, m5.large, etc.)
âœ“ DurÃ©e d'utilisation (heures/mois)
âœ“ Nombre d'instances par type
âœ“ RÃ©gion AWS de dÃ©ploiement
âœ“ Utilisation CPU moyenne (si disponible)
âœ“ Services utilisÃ©s (S3, Lambda, RDS, etc.)
âœ“ Trafic rÃ©seau (Go transfÃ©rÃ©s)
```

### **DonnÃ©es de Contexte**
```
âœ“ Mix Ã©nergÃ©tique rÃ©gional (fourni par AWS)
âœ“ PUE (Power Usage Effectiveness) du datacenter
âœ“ Facteurs d'Ã©mission Ã©lectricitÃ© par rÃ©gion
âœ“ Ã‰missions incorporÃ©es (manufacturing)
```

### **MÃ©triques Business**
```
âœ“ Nombre d'utilisateurs actifs
âœ“ Transactions/requÃªtes traitÃ©es
âœ“ Volume de donnÃ©es stockÃ©es/transfÃ©rÃ©es
âœ“ Sessions utilisateur
```

---

## ðŸ”¬ **MÃ‰THODOLOGIE DÃ‰TAILLÃ‰E**

### **Ã‰TAPE 1 : Collecte des DonnÃ©es**

#### A. Via AWS Cost & Usage Reports (CUR)
```sql
-- Configuration dans AWS Billing
1. Activer Cost & Usage Reports
2. Inclure Resource IDs
3. Format CSV/Parquet vers S3
4. GranularitÃ© horaire/quotidienne
```

#### B. Via AWS APIs
```python
# Exemple avec boto3
import boto3

ec2 = boto3.client('ec2')
cloudwatch = boto3.client('cloudwatch')

# RÃ©cupÃ©rer instances actives
instances = ec2.describe_instances()

# RÃ©cupÃ©rer mÃ©triques utilisation CPU
cpu_metrics = cloudwatch.get_metric_statistics(
    Namespace='AWS/EC2',
    MetricName='CPUUtilization',
    Dimensions=[{'Name': 'InstanceId', 'Value': instance_id}],
    StartTime=start_time,
    EndTime=end_time,
    Period=3600,
    Statistics=['Average']
)
```

### **Ã‰TAPE 2 : Calcul des Ã‰missions**

#### A. **Formule GÃ©nÃ©rale**
```
Total CO2e = Ã‰missions OpÃ©rationnelles + Ã‰missions IncorporÃ©es

Ã‰missions OpÃ©rationnelles = 
Usage Service Ã— Facteur Ã‰nergie Ã— PUE Ã— Facteur Ã‰mission RÃ©seau

Ã‰missions IncorporÃ©es = 
Ã‰missions Manufacturing Serveurs Ã— Allocation Temps d'Usage
```

#### B. **Calcul par Instance EC2**
```python
def calculer_co2_instance(instance_type, heures_usage, region, cpu_utilization=50):
    # Facteurs par type d'instance (Watts)
    WATTS_INSTANCES = {
        't2.micro': {'min': 1.0, 'max': 3.5},
        't2.small': {'min': 1.5, 'max': 5.0},
        't2.medium': {'min': 2.0, 'max': 8.5},
        'm5.large': {'min': 5.0, 'max': 15.0},
        # ... autres types
    }
    
    # Facteurs rÃ©gionaux (kgCO2e/kWh)
    FACTEURS_REGIONS = {
        'eu-west-1': 0.180,  # Irlande
        'eu-west-3': 0.056,  # Paris
        'us-east-1': 0.415,  # Virginie
        'ap-southeast-1': 0.431,  # Singapour
        # ... autres rÃ©gions
    }
    
    # Calcul consommation Ã©nergÃ©tique
    watts_min = WATTS_INSTANCES[instance_type]['min']
    watts_max = WATTS_INSTANCES[instance_type]['max']
    watts_avg = watts_min + (watts_max - watts_min) * (cpu_utilization / 100)
    
    # Consommation en kWh
    kwh = (watts_avg * heures_usage) / 1000
    
    # PUE moyen AWS â‰ˆ 1.2
    kwh_total = kwh * 1.2
    
    # Ã‰missions opÃ©rationnelles
    co2_operationnel = kwh_total * FACTEURS_REGIONS[region]
    
    # Ã‰missions incorporÃ©es (â‰ˆ 300 kgCO2e sur 4 ans)
    co2_incorpore = (300 * heures_usage) / (4 * 365 * 24)
    
    return co2_operationnel + co2_incorpore
```

### **Ã‰TAPE 3 : AgrÃ©gation et Analyse**

#### A. **Par Service AWS**
```python
def calculer_co2_total(usage_data):
    total_co2 = 0
    
    for service in usage_data:
        if service['type'] == 'EC2':
            co2 = calculer_co2_instance(
                service['instance_type'],
                service['heures'],
                service['region'],
                service.get('cpu_util', 50)
            )
        elif service['type'] == 'S3':
            co2 = calculer_co2_stockage(service['gb_stockes'], service['region'])
        elif service['type'] == 'Lambda':
            co2 = calculer_co2_lambda(service['gb_secondes'], service['region'])
        
        total_co2 += co2
    
    return total_co2
```

#### B. **MÃ©triques de Performance**
```python
def calculer_metriques(co2_total, business_metrics):
    return {
        'co2_par_utilisateur': co2_total / business_metrics['utilisateurs'],
        'co2_par_transaction': co2_total / business_metrics['transactions'],
        'co2_par_gb_data': co2_total / business_metrics['gb_transferes'],
        'intensite_carbone': co2_total / business_metrics['chiffre_affaires']
    }
```

---

## ðŸ› ï¸ **OUTILS ET IMPLÃ‰MENTATION**

### **1. AWS CCFT (RecommandÃ© pour Production)**
```bash
# AccÃ¨s via AWS CLI
aws ce get-carbon-footprint \
    --time-period Start=2024-01-01,End=2024-12-31 \
    --group-by Type=DIMENSION,Key=SERVICE

# Export CSV pour analyse
aws ce get-carbon-footprint-data-export \
    --destination-s3-bucket my-carbon-data \
    --format CSV
```

### **2. Cloud Carbon Footprint (Open Source)**
```bash
# Installation
npm install -g @cloud-carbon-footprint/cli

# Configuration AWS
export AWS_ACCESS_KEY_ID=your_key
export AWS_SECRET_ACCESS_KEY=your_secret
export AWS_REGION=eu-west-1

# ExÃ©cution
ccf --startDate 2024-01-01 --endDate 2024-12-31
```

### **3. Solution Custom**
```python
class AWSCarbonCalculator:
    def __init__(self, aws_session):
        self.session = aws_session
        self.ec2 = aws_session.client('ec2')
        self.cloudwatch = aws_session.client('cloudwatch')
        self.cur = aws_session.client('cur')
    
    def get_usage_data(self, start_date, end_date):
        # RÃ©cupÃ©rer donnÃ©es d'usage depuis CUR
        pass
    
    def calculate_emissions(self, usage_data):
        # Appliquer formules de calcul
        pass
    
    def generate_report(self, emissions_data):
        # GÃ©nÃ©rer rapport avec mÃ©triques
        pass
```

---

## ðŸ“ˆ **FACTEURS DE PRÃ‰CISION**

### **Niveau de PrÃ©cision Croissant**
1. **Basique** : Facteurs moyens par type d'instance
2. **IntermÃ©diaire** : Utilisation CPU rÃ©elle + rÃ©gion
3. **AvancÃ©** : Microarchitecture processeur + mix Ã©nergÃ©tique temps rÃ©el
4. **Expert** : PUE spÃ©cifique + Ã©missions incorporÃ©es dÃ©taillÃ©es

### **Validation des RÃ©sultats**
```python
def valider_coherence(resultats):
    # VÃ©rifications de cohÃ©rence
    if resultats['co2_par_euro'] > 10:  # Seuil d'alerte
        print("âš ï¸ IntensitÃ© carbone Ã©levÃ©e dÃ©tectÃ©e")
    
    if resultats['variation_mensuelle'] > 50:  # >50% variation
        print("âš ï¸ Variation importante Ã  investiguer")
    
    # Benchmark industrie
    benchmark_saas = 0.2  # kgCO2e par utilisateur/mois
    if resultats['co2_par_utilisateur'] > benchmark_saas:
        print("ðŸ“Š Au-dessus de la moyenne industrie")
```

---

## ðŸŽ¯ **RECOMMANDATIONS D'OPTIMISATION**

### **Actions ImmÃ©diates**
1. **Rightsizing** : Ajuster tailles instances Ã  l'usage rÃ©el
2. **Graviton** : Migrer vers processeurs ARM (20-40% plus efficaces)
3. **RÃ©gions vertes** : Prioriser eu-west-3 (Paris), eu-north-1 (Stockholm)
4. **Auto Scaling** : Ã‰viter sur-provisioning

### **Actions Moyen Terme**
1. **Serverless** : Migrer vers Lambda/Fargate
2. **Storage Tiers** : Utiliser S3 Intelligent Tiering
3. **CDN** : RÃ©duire distances rÃ©seau avec CloudFront
4. **Scheduling** : Ã‰teindre ressources non-critiques

### **MÃ©triques de Suivi**
```python
KPIs = {
    'co2_par_utilisateur_actif': 'kgCO2e/utilisateur/mois',
    'efficacite_energetique': 'kWh/transaction',
    'ratio_graviton': '% instances ARM',
    'facteur_utilisation': '% CPU moyen',
    'reduction_mensuelle': '% Ã©volution CO2'
}
```

Cette mÃ©thodologie vous permet d'obtenir une mesure prÃ©cise et actionnable de l'impact carbone de votre infrastructure AWS, avec des recommandations concrÃ¨tes d'optimisation.